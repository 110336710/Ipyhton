{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Notebook made by  \n",
    "\n",
    "|** Name** | **Student id** | **email**|\n",
    "|:- |:-|:-|\n",
    "|Ilse Lankhorst |10336710 |10336710 |\n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. \n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='link to your selfie'/>\n",
    "\n",
    "### Note\n",
    "* **Assignments without the selfies or completely filled in information will not be graded and receive 0 points.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Recap Exam\n",
    "\n",
    "This exam is meant to test how fluent or how rusty you are in Python. \n",
    "We do some simple things working with lists, counting things, and doing a bit of basic statistics.\n",
    "You may not remember everything at one. That is no problem, if you can reasonably fast find it back using Python's reference.\n",
    "\n",
    "Also, don't forget the great help that IPython can give you: TAB and ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'ASIAN', u'EXPORTERS', u'FEAR', u'DAMAGE', u'FROM', ...]\n"
     ]
    }
   ],
   "source": [
    "import re,pprint,nltk\n",
    "from __future__ import division\n",
    "from nltk.corpus import reuters \n",
    "# make a corpus of all words in the test files\n",
    "testIDs= [w for w in reuters.fileids() if w.startswith('test')]\n",
    "testWords=reuters.words(testIDs)\n",
    "testWords[:5]\n",
    "print testWords\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the questions. \n",
    "Answer them  in the code block after the question. \n",
    "\n",
    "Reuse variables that you have defined in earlier questions in later questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(1) How many words/tokens are there in testWords? And how many unique tokens/words? What is the average frequency of a word?\n",
    "Define a variable for each subquestion.\n",
    "Then print out all variables at once. Use this style for the other exercises as well.\n",
    "So something like:\n",
    "```\n",
    "NumWords = ...\n",
    "NumUnique = ...\n",
    "AvgFreq = ....\n",
    "NumWords, NumUnique, AvgFreq\n",
    "```\n",
    "Or even better with a nicely formatted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumWords = 467205 , NumUnique = 22337 , AvgFreq = 20.9161928639\n"
     ]
    }
   ],
   "source": [
    "NumWords = len(testWords)\n",
    "NumUnique = len(set(testWords))\n",
    "AvgFreq = NumWords/NumUnique\n",
    "print \"NumWords =\", NumWords, \", NumUnique =\", NumUnique,\", AvgFreq =\", AvgFreq "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) How many bigrams (a bigram is a sequence of two consequtive words)  are there in testWords? How many unique ones? What is the average bigram frequency? Explain the difference of the last two numbers with the numbers in the previous question. \n",
    "Make it easy for yourself. Just use the most \"dumb\" definition of bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumBigrams = 467204 , NumUniqueBigrams = 155763 , AvgFreqBigram = 2.99945429916\n"
     ]
    }
   ],
   "source": [
    "bigrams = []\n",
    "for i in range(len(testWords)-1):\n",
    "    bigrams.append((testWords[i], testWords[i+1]))\n",
    "    i += 1;\n",
    "\n",
    "NumBigrams = len(bigrams)\n",
    "NumUniqueBigrams = len(set(bigrams))\n",
    "AvgFreqBigram = NumBigrams/NumUniqueBigrams\n",
    "\n",
    "print \"NumBigrams =\", NumBigrams, \", NumUniqueBigrams =\", NumUniqueBigrams,\", AvgFreqBigram =\", AvgFreqBigram "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)  There are quite some tokens in testWords which are not really \"words\".\n",
    "\n",
    "Use [regular expressions](https://docs.python.org/2/library/re.html) and use the list of english stopwords which can be obtained as follows:\n",
    "\n",
    "```\n",
    "from nltk.corpus import stopwords\n",
    "# test\n",
    "stopwords.words('english')[:20]\n",
    "```\n",
    "\n",
    "Don't display too many digits behind the comma: use the `round()` function to control that.\n",
    "\n",
    "3.1. Create the list of all \"punctuation tokens\" in testWords.\n",
    "\n",
    "3.2. Create the list of all \"stopword tokens\" in testWords. Use NLTK's english stopword list.\n",
    "\n",
    "3.3. Compute the percentage of all tokens in testWords that is a punctuation and the percentage of all tokens in testWords that is a stopword.\n",
    "\n",
    "3.4. How many (as a percentage) of the UNIQUE tokens in testWords is a punctuation? How many a stopword?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55099 467205\n",
      "set([u',', u'/', u'.', u';', u':', u'?'])\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# 3.1\n",
    "punctuations = []\n",
    "for s in testWords:\n",
    "    found = re.findall(r':|;|\\.|,|!|@|\\?|%|/', s)\n",
    "    for i in found:\n",
    "        punctuations.append(i);\n",
    "        \n",
    "print len(punctuations), len(testWords)\n",
    "print set(punctuations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105739\n"
     ]
    }
   ],
   "source": [
    "# 3.2\n",
    "\n",
    "wordList = []\n",
    "for i in testWords:\n",
    "     if i in stopwords.words('english'):\n",
    "        wordList.append(i)\n",
    "        \n",
    "print len(wordList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procent punctuation: 11.4140473668 % Procent stopwords: 22.6322492268 %\n"
     ]
    }
   ],
   "source": [
    "# 3.3\n",
    "\n",
    "punctFreq = len(punctuations)/len(testWords)*100\n",
    "stopFreq = len(wordList)/len(testWords)*100\n",
    "\n",
    "print 'Procent punctuation:',punctFreq,'% Procent stopwords:', stopFreq,'%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procent punctuation: 0.0223843846533 % Procent stopwords: 0.54617898554 %\n"
     ]
    }
   ],
   "source": [
    "# 3.4\n",
    "\n",
    "punctFreq = len(set(punctuations))/len(set(testWords))*100\n",
    "stopFreq = len(set(wordList))/len(set(testWords))*100\n",
    "\n",
    "print 'Procent punctuation:',punctFreq,'% Procent stopwords:', stopFreq,'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 We will now start counting _how often_ words appear in the list `testWords`. Counting is a very important and often used tool. It is _expensive_ as it involves sorting.\n",
    "\n",
    "There are several ways to do counting, and we look at a few of them:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15048, 1, [u'the', u'the', u'the', u'the', u'the'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of times the word \"the\" occurs\n",
    "the = [x for x in testWords if x=='the']\n",
    "len(the), len(set(the)), the[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15048"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each list has a count method, which is ideal for counting\n",
    "testWords.count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'blue': 3, 'red': 2, 'yellow': 1}), 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This trick counts all items in one go and yields a dictionary\n",
    "from collections import Counter\n",
    "z = ['blue', 'red', 'blue', 'yellow', 'blue', 'red']\n",
    "Counter(z), Counter(z)['blue']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 27578), (',', 20026), ('the', 15048), ('of', 9217), ('to', 8345)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with NLTK we can make a similar datastructure\n",
    "testfd= nltk.FreqDist(testWords)\n",
    "testfd.items()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.1 Use `set()` and dict comprehension to create a dict like `testfd` using the `.count()` method\n",
    "\n",
    "3.5.2 You now have 3 ways to make a wordcount dictionary. Use the timing functions to see which one is the fastest.\n",
    "\n",
    "3.5.3 Which percentage of the UNIQUE tokens in testWords is a hapax (i.e. occurs only once in testWords)?\n",
    "\n",
    "3.5.4 Which percentage of the   tokens in testWords is a hapax? \n",
    "\n",
    "3.5.5 Explain why the following test returns True: `len(testfd)==len(set(testWords))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'Arbitration': 1, u'limited': 1, u'restraining': 1, u'scratch': 1, u'forbidden': 1, u'vermin': 1, u'focus': 1, u'by': 17, u'month': 3, u'four': 2, u'protest': 1, u'it': 17, u'DEMAND': 1, u'talks': 2, u'rot': 1, u'Until': 1, u'row': 1, u'whose': 2, u'21st': 1, u'Business': 1, u'fiscal': 2, u'effort': 2, u'pledged': 1, u'CPO': 5, u'opportunities': 1, u'W': 1, u'Glass': 1, u'program': 1, u'Western': 2, u'marks': 7, u'include': 1, u'defuse': 1, u'worth': 1, u'Matsushita': 1, u'deliberations': 1, u'ENDS': 1, u'Agency': 1, u'shipment': 1, u'advantage': 1, u'far': 1, u'Industry': 4, u'rise': 2, u'telephone': 1, u'aware': 1, u'handling': 2, u'deficit': 1, u'fall': 1, u'vastly': 1, u'exporters': 2, u'PACT': 1, u'Continental': 1, u'hour': 1, u'called': 1, u'crops': 1, u'Osaka': 1, u'manager': 1, u'Unofficial': 1, u'sentiment': 1, u'domestically': 1, u'planning': 1, u'small': 2, u'provided': 1, u'Paul': 1, u'He': 5, u'noted': 2, u'programme': 1, u'prevent': 2, u'smaller': 2, u'595': 1, u'dealing': 1, u'VERMIN': 1, u'estimates': 1, u'direct': 1, u'PCT': 1, u'FOREIGN': 1, u'feasibility': 1, u'go': 2, u'second': 3, u'cost': 4, u'Northwest': 1, u'further': 5, u'estimated': 2, u'port': 2, u'Minister': 5, u'bold': 2, u'cargo': 1, u'what': 1, u'Korea': 4, u'revised': 1, u'appear': 1, u'rate': 1, u'decisions': 1, u'reaching': 1, u'profitability': 1, u'spokesman': 4, u'Now': 1, u'version': 1, u'run': 1, u'Resources': 1, u'then': 1, u'marketing': 1, u'supplies': 2, u'firms': 1, u'Hasrul': 1, u'boost': 3, u'public': 1, u'WESTERN': 1, u'outgoing': 1, u'Economics': 1, u'COMMODITY': 1, u'exchange': 13, u'licences': 1, u'pushing': 1, u'commercial': 2, u'We': 10, u'here': 1, u'Up': 1, u'reported': 1, u'separate': 1, u'GRA': 1, u'thirds': 1, u'Taiwan': 5, u'supplying': 1, u'wait': 1, u'lose': 2, u'38': 1, u'MC': 1, u'905': 1, u'shift': 1, u'study': 1, u'30': 3, u'restructuring': 1, u'35': 1, u'later': 1, u'credit': 1, u'products': 3, u'analysts': 4, u'Department': 3, u'sawn': 1, u'action': 3, u'liquidity': 4, u'changes': 3, u'Makoto': 1, u'named': 1, u'Group': 1, u'projection': 1, u'unrecoverable': 1, u'deputy': 1, u'semiconductors': 3, u'while': 3, u'332': 1, u'scaled': 1, u'put': 2, u'TO': 2, u'SUMI': 1, u'Tom': 1, u'ailing': 1, u'Wales': 1, u'sugar': 1, u'establish': 1, u'>': 6, u'market': 7, u'Sumitomo': 14, u'Europe': 1, u'RIFT': 1, u'confidence': 1, u'Australia': 3, u'from': 15, u'August': 2, u'would': 8, u'&': 9, u'visit': 1, u'two': 10, u'next': 2, u'few': 1, u'grades': 1, u'Corp': 4, u'correspondents': 1, u'themselves': 1, u'bill': 1, u'markets': 3, u'until': 2, u'today': 6, u'more': 2, u'spokesmen': 1, u'beyond': 1, u'October': 2, u'dlrs': 13, u'started': 1, u'Philippines': 1, u'Others': 1, u'infusion': 1, u'hurt': 1, u'disruption': 2, u'American': 3, u'carrying': 1, u'stick': 1, u'sharply': 1, u'separates': 1, u'known': 1, u'central': 4, u'cases': 2, u'95': 1, u'Victoria': 1, u'must': 2, u'states': 1, u'valued': 1, u'SUMITOMO': 1, u'Kuroda': 1, u'this': 6, u'lapse': 1, u'work': 2, u'Taiwanese': 1, u'Pacific': 1, u'remain': 1, u'minimum': 1, u'nine': 1, u'can': 3, u'island': 1, u'following': 2, u'making': 1, u'newspapers': 1, u'purchases': 1, u'prompt': 1, u'acquire': 1, u'Northern': 1, u'Dlrs': 1, u'Federal': 1, u'of': 108, u'allowed': 2, u'share': 4, u'550': 2, u'DAILY': 1, u'high': 1, u'effectively': 1, u'reserves': 1, u'want': 4, u'MITI': 5, u'BAN': 1, u'Party': 1, u'Australian': 1, u'Several': 1, u'clothing': 1, u'occur': 1, u'end': 3, u'Federation': 1, u'lame': 1, u'country': 2, u'divided': 1, u'six': 1, u'damage': 1, u'1': 11, u'located': 1, u'976': 1, u'earnings': 2, u'interview': 2, u'ensure': 1, u'if': 3, u'goods': 2, u'REVISE': 1, u'stock': 1, u'A': 4, u'plant': 1, u'kilowatt': 1, u'may': 2, u'digesting': 1, u'after': 2, u'TERM': 1, u'timber': 1, u'reflect': 1, u'barriers': 1, u'membership': 1, u'produce': 1, u'waves': 1, u'Swiss': 1, u'such': 3, u'STOCKS': 1, u'promotion': 1, u'BANK': 1, u'a': 69, u'short': 5, u'natural': 3, u'third': 1, u'Murtha': 1, u'Rachmat': 1, u'Japanese': 7, u'commodities': 1, u'coal': 2, u'chief': 1, u'maintain': 1, u'so': 4, u'revise': 1, u'deterioration': 1, u'enter': 1, u'banks': 4, u'first': 8, u'began': 1, u'operations': 1, u'hands': 1, u'infant': 1, u'holds': 2, u'help': 1, u'office': 1, u'devote': 1, u'over': 4, u'altogether': 1, u'Smith': 1, u'soon': 1, u'trade': 15, u'produced': 1, u'ended': 1, u'paper': 2, u'through': 2, u'4': 2, u'committee': 1, u'left': 1, u'Atlas': 8, u'still': 3, u'its': 16, u'Sheen': 1, u'before': 2, u'25': 1, u'26': 1, u'27': 2, u'March': 2, u'21': 2, u'Transactions': 1, u'reluctant': 1, u'del': 1, u'll': 1, u'AUSTRALIAN': 1, u'ships': 1, u'29': 1, u'pct': 25, u'better': 2, u'Pressure': 1, u'lt': 9, u'production': 2, u'policy': 1, u'ours': 1, u'weeks': 1, u'main': 1, u'might': 4, u'Grace': 1, u'stepped': 1, u'wouldn': 1, u'them': 2, u'good': 1, u'affected': 1, u'halt': 1, u'prevented': 1, u'outlined': 1, u'largest': 4, u'Michael': 1, u'cover': 1, u'answer': 1, u'walls': 1, u'preservation': 2, u'they': 11, u'half': 2, u'not': 8, u'now': 2, u'day': 2, u'association': 1, u'FIRST': 1, u'term': 5, u'AUSTRALIA': 1, u'Liberal': 1, u'Yasuhiro': 1, u'EAT': 1, u'reasonably': 1, u'countries': 2, u'DAMAGE': 1, u'vegetables': 1, u'MAY': 1, u'Labour': 1, u'stopped': 1, u'gamble': 1, u'Council': 1, u'each': 3, u'did': 1, u'went': 1, u'economy': 2, u'Agriculture': 1, u'ports': 4, u'right': 1, u'mean': 1, u'week': 4, u'lifted': 1, u'financial': 4, u'individuals': 1, u'Holdings': 2, u'Mounting': 1, u'energy': 6, u',\"': 15, u'Mills': 1, u'related': 2, u'89': 1, u'trading': 7, u'juggling': 1, u'inflict': 1, u'year': 13, u'our': 1, u'80': 1, u'Kong': 5, u'87': 1, u'out': 4, u'large': 2, u'initiatives': 1, u'container': 1, u'network': 2, u\"'\": 44, u'factors': 1, u'Agreement': 1, u'vessels': 1, u'increase': 3, u'encourage': 2, u'broker': 1, u'China': 3, u'7': 3, u'exporting': 1, u'Article': 1, u'electronics': 4, u'Ministry': 2, u'Tug': 1, u'530': 1, u'earlier': 1, u'alleged': 2, u'curbs': 2, u'state': 1, u'This': 1, u'Indonesia': 6, u'seventh': 1, u'yesterday': 2, u'geared': 1, u'clarify': 1, u'.,\"': 1, u'lucrative': 1, u'members': 1, u'tightening': 1, u'repurchase': 2, u'ore': 1, u'business': 10, u'steering': 2, u'.-': 2, u'producers': 1, u'fixed': 1, u'Kembla': 1, u'ministry': 2, u'record': 1, u'discussing': 1, u'could': 3, u'impose': 1, u'days': 2, u'keen': 1, u'length': 1, u'fruit': 1, u'place': 3, u'businessmen': 4, u'routes': 1, u'JAPAN': 2, u'outcry': 1, u'stimulate': 1, u'physicals': 1, u'copper': 3, u'major': 2, u'already': 1, u'protectionist': 1, u'450': 1, u'question': 2, u'accruing': 1, u'primary': 1, u'owned': 1, u'one': 4, u'Rubber': 1, u'liquefied': 1, u'relations': 2, u'>.': 3, u'vote': 1, u'SAYS': 2, u'open': 4, u'long': 3, u'Capel': 1, u'city': 1, u'\"': 21, u'Monday': 2, u'their': 6, u'introduction': 1, u'leading': 1, u'trillion': 1, u'Commercial': 1, u'system': 2, u'least': 2, u'TRADE': 1, u'plentiful': 1, u'needed': 1, u'pineapples': 1, u'2': 4, u'rates': 1, u'ASIAN': 1, u'184': 1, u'structural': 1, u'STILL': 1, u'LANKA': 1, u'too': 2, u'mining': 2, u'selling': 1, u'statement': 4, u'that': 16, u'Gottardo': 2, u'Trades': 1, u'Retaliation': 1, u'wisdom': 1, u'No': 1, u'biggest': 2, u'part': 1, u'RISING': 1, u'bank': 12, u'If': 2, u'years': 3, u'SHIP': 1, u'Democratic': 1, u'than': 5, u'10': 1, u'kind': 2, u'12': 5, u'15': 1, u'industrial': 1, u'Canberra': 1, u'widened': 1, u'19': 1, u'18': 1, u'Mexico': 1, u'diplomatic': 1, u'likely': 4, u'nations': 1, u'claim': 1, u'matter': 1, u'compensation': 1, u'Officials': 1, u'CHINA': 1, u'venture': 1, u'were': 4, u'stricter': 1, u'outcome': 1, u'greater': 1, u'acquisition': 1, u'275': 1, u'and': 69, u'futures': 1, u'EXTENSION': 1, u'largely': 1, u'imports': 7, u'cautiously': 2, u'conventional': 1, u'mine': 3, u'It': 9, u'negotiations': 2, u'raw': 1, u'say': 2, u'medium': 1, u'have': 5, u';': 9, u'need': 1, u'seen': 1, u'turn': 1, u'BAIL': 1, u'any': 1, u'relatively': 1, u'sell': 1, u'forced': 1, u'John': 1, u'RECOVERY': 1, u'able': 2, u'Food': 1, u'Goldman': 1, u'After': 1, u'-': 29, u'officers': 1, u'billion': 22, u'investment': 2, u'walk': 1, u'also': 11, u'concerns': 1, u'45': 1, u'chairman': 2, u'which': 5, u'funds': 2, u'new': 6, u'outlook': 2, u'subject': 1, u'blunt': 1, u'Bank': 2, u'province': 1, u'added': 2, u'unless': 1, u'allow': 2, u'James': 1, u'measures': 2, u'Button': 2, u'expires': 1, u'paid': 1, u'most': 3, u'said': 79, u'Grain': 1, u'but': 7, u'significant': 1, u'MN': 1, u'The': 28, u'U': 25, u'Asked': 1, u'strategies': 1, u'Bond': 4, u'don': 1, u'dealers': 1, u'considered': 2, u'average': 1, u'That': 2, u'Some': 2, u'sale': 1, u'kl': 1, u'looked': 1, u'OUT': 1, u'Banca': 1, u'R': 1, u'Export': 1, u'link': 1, u'senior': 2, u'latest': 1, u'review': 1, u'reserve': 1, u'surplus': 3, u'gold': 5, u'chances': 1, u'meetings': 1, u'memorandum': 1, u'Wilson': 1, u'friction': 1, u'ending': 1, u'Reuters': 4, u'businesses': 1, u'subsidiary': 2, u'TENDER': 1, u'Bundesbank': 7, u'aggressive': 1, u'Has': 1, u'bail': 1, u'find': 1, u'Harahap': 3, u'European': 2, u'impact': 1, u'Regulations': 1, u'Exports': 1, u'believe': 1, u'based': 1, u'producer': 3, u'Meanwhile': 2, u'merger': 4, u'(': 12, u'debts': 1, u'credited': 1, u'3': 5, u'should': 2, u'only': 3, u'SHARPLY': 1, u'equity': 1, u'8': 3, u'rice': 1, u'local': 1, u'merged': 1, u'dispute': 4, u'Prime': 1, u'do': 4, u'exports': 8, u'move': 4, u'hit': 3, u'contracts': 1, u'commodity': 1, u'Annual': 1, u'expects': 1, u'crude': 2, u'Industrial': 1, u'Products': 2, u'nearly': 1, u'reporters': 1, u'report': 1, u'during': 2, u'awaiting': 1, u'River': 1, u'net': 3, u'14': 2, u'Smithson': 2, u'17': 1, u'tobacco': 1, u'held': 1, u'SUPPORTS': 1, u'decade': 1, u'Move': 1, u'Washington': 1, u'retaliation': 1, u'taxes': 1, u'worried': 1, u'banking': 2, u'bad': 1, u'withdrawal': 1, u'ban': 2, u'including': 3, u'told': 5, u'where': 2, u'view': 3, u'duck': 1, u'requirement': 1, u'Sogo': 4, u'grain': 1, u'unions': 1, u'tree': 1, u'national': 1, u'INDONESIA': 2, u'accord': 1, u'around': 3, u'Lawrence': 1, u'see': 1, u'officials': 6, u'GRAIN': 1, u'result': 1, u'Sydney': 1, u'tender': 1, u'APPROVAL': 1, u'calendar': 3, u'ITA': 3, u'declined': 1, u'concern': 1, u'project': 1, u'Indonesian': 4, u'Subroto': 2, u'capacity': 1, u'parent': 1, u'registering': 1, u'reform': 1, u'lots': 1, u'nuclear': 1, u'Nainggolan': 3, u'currently': 2, u'Sumatran': 1, u'BUT': 1, u'forecast': 1, u'outside': 1, u'future': 1, u'various': 2, u'Representative': 1, u'use': 1, u'between': 9, u'Prices': 1, u'import': 4, u'electric': 2, u'Steagall': 1, u'ruling': 1, u'CONSIDERING': 1, u'WMNG': 1, u'comparable': 1, u'Natural': 1, u'creating': 1, u'FOR': 1, u'initially': 1, u'Heiwa': 4, u'pesos': 1, u'weak': 1, u'however': 1, u'Securities': 3, u'381': 1, u'S': 27, u'coffee': 5, u'FOB': 3, u'calling': 1, u'20': 2, u'users': 1, u'understanding': 1, u'1987': 2, u'undermine': 1, u'Among': 1, u'climate': 1, u'last': 4, u'limits': 1, u'Mt': 1, u'C': 1, u'deregulation': 2, u'taking': 2, u'23': 4, u'has': 10, u'movement': 1, u'against': 4, u'foreign': 2, u'Malaysia': 3, u's': 37, u'figures': 1, u'WIDENS': 1, u'argue': 1, u'traded': 2, u'asked': 1, u'BILLION': 1, u'among': 2, u'reduce': 2, u'tough': 1, u'key': 1, u'Japan': 15, u'supply': 3, u'28': 1, u'loan': 1, u'Ltd': 7, u'Sachs': 1, u'575': 1, u',': 141, u'60': 2, u'agreed': 2, u'canned': 1, u'64': 1, u'65': 2, u'66': 1, u'allocated': 1, u'trust': 1, u'effective': 1, u'EXPAND': 1, u'600': 1, u'considering': 1, u'decline': 1, u'provinces': 1, u'cities': 1, u'manoeuvres': 1, u'kilolitres': 1, u'beef': 1, u'basis': 1, u'create': 1, u'locally': 1, u'Koh': 1, u'due': 3, u'But': 9, u'strategy': 1, u'confident': 1, u'willing': 1, u'slowly': 1, u'change': 1, u'interest': 3, u'Nuclear': 1, u'expected': 5, u'outweighed': 1, u'entered': 1, u'waste': 2, u'containers': 1, u'board': 1, u'firm': 2, u'partnership': 1, u'468': 1, u'EXCHANGE': 1, u'SRI': 1, u'gas': 2, u'block': 1, u'sales': 1, u'bulk': 1, u'Benson': 1, u'finished': 1, u'minister': 2, u'bidding': 1, u'demand': 6, u'prices': 3, u'improved': 2, u'despite': 3, u'general': 2, u'Moslem': 1, u'those': 2, u'And': 4, u'Goodall': 1, u'troubled': 1, u'Co': 6, u'ahead': 1, u'Deputy': 1, u'these': 1, u'expanded': 2, u'mln': 11, u'elections': 1, u'value': 1, u'will': 24, u'near': 1, u'warning': 1, u'safely': 1, u'Saleh': 2, u'withdrawing': 1, u'Hong': 5, u'Energy': 2, u'launched': 2, u'mistake': 1, u'seven': 3, u'losses': 1, u've': 1, u'metropolitan': 1, u'century': 1, u'is': 24, u'Mines': 1, u'Adelaide': 1, u'according': 1, u'disappointing': 1, u'Tin': 1, u'optimistic': 1, u'in': 79, u'ready': 1, u'tonne': 3, u'BONA': 1, u'technology': 1, u'DOWNWARDS': 1, u'movements': 2, u'confirmed': 1, u'Board': 1, u'grant': 1, u')': 8, u'pay': 5, u'make': 3, u'textile': 1, u'QUICK': 1, u'enquiries': 1, u'patient': 1, u'virtually': 1, u'widely': 1, u'big': 1, u'9': 6, u'President': 1, u'struggling': 1, u'rupiah': 2, u'ENERGY': 1, u'conflict': 1, u'NSW': 5, u'breakdown': 1, u'Development': 1, u'oil': 11, u'temporary': 1, u'partners': 1, u'Commodity': 1, u'swell': 1, u'effect': 1, u'director': 1, u'helped': 1, u'000': 2, u'purpose': 1, u'IN': 3, u'Banks': 3, u'blamed': 1, u'expand': 4, u'recent': 2, u'centred': 1, u'fasting': 1, u'lower': 3, u'drain': 1, u'off': 4, u'Latin': 1, u'disrupted': 2, u'F': 1, u'whole': 1, u'well': 1, u'Ramadan': 1, u'Janunary': 1, u'MERGER': 1, u'materials': 1, u'Colombo': 1, u'gain': 1, u'In': 4, u'very': 2, u'position': 2, u'Kleinwort': 2, u'Total': 1, u'Port': 1, u'meet': 2, u'things': 1, u'AIMS': 1, u'serious': 2, u'proposed': 1, u'less': 1, u'being': 4, u'money': 1, u'accurate': 1, u'entering': 1, u'domestic': 3, u'mid': 1, u'inadequate': 1, u'sources': 4, u'TIN': 1, u'showed': 1, u'ounces': 1, u'Meiko': 1, u'followed': 1, u'THAI': 1, u'Territory': 1, u'.': 217, u'consume': 1, u'profitable': 2, u'cut': 2, u'tonnes': 7, u'majority': 1, u'rose': 1, u'workers': 1, u'Friday': 1, u'had': 10, u'LONG': 1, u'the': 146, u'instrument': 1, u'questioned': 1, u'Newcastle': 1, u'bond': 1, u'31': 1, u'east': 1, u'lending': 1, u'gave': 1, u'MINING': 2, u'Reuter': 1, u'Last': 2, u'to': 92, u'emergency': 1, u'government': 3, u'hard': 2, u'bid': 1, u'when': 1, u'possible': 3, u'downtrend': 1, u'possibly': 2, u'totalled': 1, u'five': 4, u'T': 2, u'Threat': 1, u'fledgling': 1, u'crumbling': 1, u'59': 1, u'emergence': 1, u'accepted': 1, u'PORTS': 1, u'disadvantage': 1, u'loss': 3, u'quickly': 3, u'effectiveness': 1, u'necessary': 1, u'58': 1, u'semi': 1, u'Exchange': 2, u'efficiency': 1, u'56': 1, u'51': 1, u'unnecessary': 1, u'53': 2, u'52': 1, u'securities': 8, u'traders': 3, u'Trading': 2, u'either': 1, u'follows': 1, u'output': 2, u'security': 1, u'works': 1, u'soft': 1, u'57': 1, u'),': 4, u'survey': 1, u'capitals': 1, u'methods': 1, u'jewellery': 1, u'existing': 1, u'creation': 1, u'imposed': 1, u'back': 3, u'competition': 1, u'50': 2, u'supplementary': 1, u'Commission': 1, u'growth': 2, u'export': 3, u'serves': 1, u'context': 1, u'International': 4, u'Bundey': 1, u'pacts': 1, u'Dealers': 1, u'delivered': 1, u'total': 2, u'WMC': 3, u'contacts': 1, u'ATLC': 1, u'decision': 4, u'Safe': 1, u'/': 4, u'wrong': 1, u'everything': 1, u'continue': 1, u'kms': 1, u'unit': 1, u'pact': 5, u'GETS': 1, u'participation': 1, u't': 2, u'regain': 1, u'be': 20, u'pepper': 1, u'who': 1, u'wheat': 1, u'USDA': 1, u'power': 2, u'baht': 3, u'300': 1, u'sixth': 3, u'shortage': 1, u'continuing': 1, u'agreement': 2, u'Daily': 1, u'pressure': 1, u'many': 2, u'expire': 1, u'although': 2, u'loans': 3, u'properties': 1, u'Electric': 1, u'hearing': 1, u'on': 25, u'about': 5, u'quarter': 3, u'WHEAT': 1, u'Paian': 1, u'world': 5, u'package': 2, u'December': 2, u'industry': 1, u'months': 3, u'MARKS': 1, u'shipping': 3, u'Trade': 5, u'extension': 4, u'range': 1, u'fell': 1, u'plus': 1, u'stand': 1, u'BUNDESBANK': 1, u'tariffs': 5, u'introduced': 1, u'or': 9, u'additives': 1, u'AT': 1, u'EXPORTERS': 1, u'Fed': 1, u'Simon': 1, u'plenty': 1, u'amounted': 1, u'yen': 2, u'SUBROTO': 1, u'into': 3, u'within': 1, u'Two': 1, u'three': 3, u'down': 1, u'because': 4, u'been': 10, u'repaid': 1, u'NEW': 1, u'refined': 1, u'Rotterdam': 1, u'OPEN': 1, u'branch': 2, u'1986': 6, u'maize': 1, u'1985': 5, u'.,': 1, u'Finance': 1, u'analyst': 3, u'area': 1, u'spending': 2, u'.\"': 5, u'support': 2, u'Cebu': 1, u'ALLOCATES': 1, u'1988': 1, u'approved': 1, u'start': 4, u'avowed': 1, u'much': 2, u'development': 3, u'Asia': 1, u'lot': 1, u'crews': 1, u'resulted': 1, u'call': 2, u'Reserve': 1, u'was': 16, u'subsidiaries': 2, u'HIT': 1, u'depressed': 1, u'Robusta': 1, u'ago': 2, u'leach': 1, u'buy': 1, u'complete': 1, u'manufacturers': 1, u'January': 1, u'allocation': 1, u'6': 9, u'Malaysian': 2, u'MINE': 1, u'extended': 1, u'hoped': 1, u'delivery': 3, u'failure': 1, u'economic': 2, u'CORP': 1, u'DEFICIT': 1, u'Physical': 1, u'hopes': 1, u'FROM': 2, u'trying': 1, u'with': 17, u'junior': 1, u'Thailand': 2, u'he': 9, u'delegation': 1, u'stocks': 1, u'made': 3, u'joint': 1, u'home': 1, u'whether': 1, u'Consolidated': 1, u'official': 3, u'bids': 1, u'up': 9, u'signed': 1, u'lead': 2, u'placed': 1, u'below': 3, u'Much': 1, u'exploration': 1, u'500': 4, u'how': 2, u'They': 6, u'fluctuations': 1, u'BOND': 1, u'similar': 3, u'clear': 1, u'750': 1, u'expect': 1, u'Cargo': 1, u'his': 2, u'strengthening': 1, u'SEES': 1, u'CIF': 1, u'GOLD': 1, u'certain': 1, u'universal': 2, u'measure': 1, u'remove': 1, u'an': 11, u'as': 10, u'sometime': 1, u'Masbate': 1, u'at': 16, u'budget': 1, u'New': 1, u'some': 6, u'accounting': 1, u'moves': 2, u'pit': 1, u'FEAR': 1, u'are': 18, u'forward': 2, u'Mining': 2, u'compared': 1, u'raised': 1, u'us': 2, u'palm': 7, u'no': 2, u'May': 1, u'personnel': 1, u'44': 1, u'Tokyo': 3, u'storage': 2, u'treatment': 1, u'40': 1, u'teams': 1, u'rubber': 8, u'ATLAS': 1, u'tin': 1, u'other': 4, u'5': 2, u'details': 1, u'holding': 1, u'department': 1, u'tie': 1, u'erosion': 1, u'company': 4, u'Like': 1, u'trades': 1, u'seriousness': 1, u'felt': 1, u'problems': 2, u'shown': 1, u'Nakasone': 1, u'replace': 1, u'April': 5, u'Komatsu': 9, u'INDONESIAN': 1, u'disappearing': 1, u'absorbing': 1, u'Act': 2, u'QUARTER': 1, u'sides': 2, u'South': 5, u'building': 1, u'desposits': 1, u'for': 30, u'fund': 1, u'we': 6, u'PRICE': 2, u'fears': 1, u'June': 1, u'flag': 1, u'solve': 1, u'2000': 1, u'status': 1, u'Asian': 1, u'time': 5, u'push': 1, u'international': 1, u'overseas': 2, u'laws': 1, u'brokers': 1}\n"
     ]
    }
   ],
   "source": [
    "# 3.5.1\n",
    "n = testWords[:4000]\n",
    "count_list = dict((i, n.count(i)) for i in set(n))\n",
    "\n",
    "print count_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter() takes : 0.00156807899475\n",
      "FreqDist() takes : 0.00158596038818\n",
      "Set Comprehension takes : 0.256315946579\n"
     ]
    }
   ],
   "source": [
    "# 3.5.2\n",
    "from collections import Counter\n",
    "import time\n",
    "n = testWords[:500]\n",
    "\n",
    "start = time.time()\n",
    "Counter(n)\n",
    "end = time.time()\n",
    "print 'Counter() takes :',(end - start)\n",
    "\n",
    "start = time.time()\n",
    "testfd= nltk.FreqDist(n)\n",
    "end = time.time()\n",
    "print 'FreqDist() takes :',(end - start)\n",
    "\n",
    "start = time.time()\n",
    "dict((i, n.count(i)) for i in set(n))\n",
    "end = time.time()\n",
    "print 'Set Comprehension takes :',(end - start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.5930902111\n"
     ]
    }
   ],
   "source": [
    "# 3.5.3\n",
    "n = testWords[:1200]\n",
    "d = dict((i, n.count(i)) for i in set(n))\n",
    "\n",
    "hapax = []\n",
    "\n",
    "for word,x in d.items():\n",
    "    if x == 1:\n",
    "        hapax.append(word)\n",
    "\n",
    "print len(hapax)/len(set(n))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.0833333333\n"
     ]
    }
   ],
   "source": [
    "# 3.5.4 \n",
    "n = testWords[:1200]\n",
    "d = dict((i, n.count(i)) for i in set(n))\n",
    "\n",
    "hapax = []\n",
    "\n",
    "for word,x in d.items():\n",
    "    if x == 1:\n",
    "        hapax.append(word)\n",
    "\n",
    "print len(hapax)/len(n)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.5.5\n",
    "\n",
    "# Set returns a unique list, whilst testfd counts every occurance of the words and thus should be the same length as \n",
    "# the unique list. Therfore the statement returns true. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Count the tokens in testWords. Make an estimate of the following probability: given a string t, if we draw an arbitrary  token from testWords, what is the chance that it equals t?\n",
    "\n",
    "Program it as a function prob(str).\n",
    "Give an example of a high and of a low probability word.\n",
    "\n",
    "Does prob work on every input string?\n",
    "\n",
    "Test that 'the probabilities add up to 1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high probability: \".\" ( 0.05425 %)\n",
      "low probability: \"Arbitration\" ( 0.00025 %)\n",
      "total probabilty: 1.0\n"
     ]
    }
   ],
   "source": [
    "n = testWords[:4000]\n",
    "d = dict((i, n.count(i)) for i in set(n))\n",
    "\n",
    "high = sorted(d.items(), key=lambda x:x[1], reverse=True)[0]\n",
    "low = sorted(d.items(), key=lambda x:x[1])[0]\n",
    "\n",
    "print 'high probability: \"'+high[0]+'\" (',high[1]/len(n),'%)'\n",
    "print 'low probability: \"'+low[0]+'\" (',low[1]/len(n),'%)'\n",
    "\n",
    "i = 0;\n",
    "for word,x in d.items():\n",
    "    i += x/len(n)\n",
    "print 'total probabilty:', i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Suppose we have printed out testWords  using exactly one space between each two tokens. Suppose we have covered a wall with this string. Now you throw a dart missile on this wall. Assume that it always hits exactly one character, which is either a space (inserted by our printing process) or a character in a token.\n",
    "\n",
    "5.1 What is the probability that it hits a space?\n",
    "\n",
    "5.2 Define a function prob(n) which for integer n returns the probability that the missile hits a token of length n.\n",
    "\n",
    "5.3 Nicely print out a table of the form \"n,  prob(n)\" which for each n returns   prob(n). Format it well, and truncate numbers. Bonus points for those who make a plot.\n",
    "\n",
    "5.3.1 Write a good test which indicates that prob(n) works correctly.\n",
    "\n",
    "5.4 What is the probability that it hits a stopword?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.32893254\n",
      "3.91908905084\n"
     ]
    }
   ],
   "source": [
    "# 5.1\n",
    "n = testWords\n",
    "spaces = len(n)-1\n",
    "characters = 0\n",
    "\n",
    "for i in n:\n",
    "    characters += len(i)\n",
    "    \n",
    "total = spaces + characters\n",
    "chance = spaces/total*100\n",
    "\n",
    "print chance\n",
    "print characters/len(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0485601478\n"
     ]
    }
   ],
   "source": [
    "# 5.2\n",
    "n = testWords\n",
    "\n",
    "def prob(n, wordList):\n",
    "    wordsFound = []\n",
    "    characters = 0\n",
    "    \n",
    "    for i in wordList:\n",
    "        characters += len(i)\n",
    "        if len(i) == n:\n",
    "            wordsFound.append(i)\n",
    "    \n",
    "    # List all valid words     \n",
    "    probChar = (100-chance)/100\n",
    "    probWord = len(wordsFound)/len(wordList)*probChar\n",
    "    avgWordLength = characters/len(wordList) \n",
    "    \n",
    "    # Correct for the lengt of the word e.g. a word of 200 char is easer to hit than a word of 3 char\n",
    "    probHit = probWord/avgWordLength*n*100\n",
    "    \n",
    "    return probHit\n",
    "        \n",
    "print prob(7, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.17483602541\n",
      "6.3866763089\n",
      "11.1079347426\n",
      "10.4348492008\n",
      "7.95506265278\n",
      "7.89192688957\n",
      "9.0485601478\n",
      "7.79663583414\n",
      "5.82123920143\n",
      "4.07097312618\n",
      "2.38836805148\n"
     ]
    }
   ],
   "source": [
    "# 5.3\n",
    "\n",
    "for i in range(1,12):\n",
    "    print prob(i, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.1794131861\n"
     ]
    }
   ],
   "source": [
    "# 5.4\n",
    "n = testWords[:1000]\n",
    "\n",
    "def prob(n, wordList):\n",
    "    characters = 0\n",
    "    stopCharacters = 0\n",
    "    stopWords = []\n",
    "    \n",
    "    for i in wordList:\n",
    "         if i in stopwords.words('english'):\n",
    "            stopWords.append(i)\n",
    "    \n",
    "    for i in wordList:\n",
    "        characters += len(i)\n",
    "        \n",
    "    for i in stopWords:\n",
    "        stopCharacters += len(i)\n",
    "    \n",
    "    avgWord = characters/len(wordList)\n",
    "    avgStop = stopCharacters/len(stopWords)\n",
    "    \n",
    "    probChar = (100-chance)/100\n",
    "    probStop = len(stopWords)/len(wordList)\n",
    "    \n",
    "    chanceStop = probStop/avgWord*avgStop*probChar*100\n",
    "    \n",
    "    return chanceStop\n",
    "        \n",
    "print prob(7, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS (if you have time left or got bored)\n",
    "\n",
    "Show that the  words in testWords have a Zipfian distribution. Count the words, order them by their frequency. Plot the log(frequency) times log(index of the word). \n",
    "\n",
    "Use `% matplotlib inline` to display the figure in the notebook.\n",
    "\n",
    "Is it a straight line?\n",
    "\n",
    "Now do the same for the unigrams and the bigrams together in one list. Is the plot \"better\"? What does 'better' mean here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
